# configs/model/vit/deit_base.yaml
defaults:
  - transformer/base_transformer
  # - _self_ # Uncomment if you need to reference other keys in this file

name: deit_base
type: vision_transformer # This could potentially be moved to base_transformer if all vit models are vision_transformers
architecture: deit # Overrides base_transformer's 'transformer'

# Model parameters
params:
  img_size: 224 # Overrides base_transformer's 224
  # patch_size: 16 # Inherited from base_transformer
  in_chans: 1  # Grayscale thyroid images
  # num_classes: 2 # Inherited from base
  embed_dim: 768  # Base model dimension
  depth: 12
  num_heads: 12  # 768 / 64 = 12
  mlp_ratio: 4.0
  qkv_bias: true
  representation_size: null
  distilled: true  # DeiT uses distillation
  drop_rate: 0.0
  attn_drop_rate: 0.0
  drop_path_rate: 0.1  # Stochastic depth (may increase for larger model)
  embed_layer: PatchEmbed
  norm_layer: LayerNorm
  act_layer: GELU
  weight_init: trunc_normal
  class_token: true
  distillation_token: true  # DeiT specific
  pos_embed_type: learnable
  pool_type: cls
  
# Pretrained settings
# pretrained: true # Inherited from base
pretrained_cfg:
  model_name: "deit_base_patch16_224"
  url: "https://dl.fbaipublicfiles.com/deit/deit_base_patch16_224-b5f2ef4d.pth"
  num_classes: 1000
  input_size: [3, 224, 224]
  interpolate_pos_embed: true
  strict: false  # Allow loading with different num_classes
  
# Knowledge distillation settings
distillation:
  teacher_model: null  # Can specify a teacher model
  alpha: 0.5  # Distillation loss weight
  temperature: 3.0
  
# Attention visualization
attention:
  save_attention_maps: true
  visualize_layers: [11]  # Last layer
  
# Model initialization
init:
  mode: trunc_normal
  std: 0.02
  
# Quality-aware preprocessing
quality_aware: true

# Expected parameter count: ~86M
# Note: Base model may need reduced batch size due to memory