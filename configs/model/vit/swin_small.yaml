# Swin-Small configuration
# ~50M parameters, balanced performance for medical imaging

defaults:
  - ../transformer/base_transformer
  # - _self_

name: swin_small
type: swin
# architecture: vit # Inherited from base_transformer as 'transformer'
params:
  # Architecture parameters
  img_size: 256 # Overrides base_transformer's 224
  patch_size: 4 # Overrides base_transformer's 16
  in_chans: 1  # Grayscale medical images
  # num_classes: 2 # Inherited from base
  embed_dim: 96
  depths: [2, 2, 18, 2]  # Deeper than tiny
  num_heads: [3, 6, 12, 24]
  window_size: 7
  mlp_ratio: 4.0
  
  # Regularization (stronger for larger model)
  drop_rate: 0.0
  attn_drop_rate: 0.0
  drop_path_rate: 0.3  # Increased stochastic depth
  
  # Advanced features
  qkv_bias: true
  qk_scale: null
  ape: false
  patch_norm: true
  use_checkpoint: false  # Enable if memory constrained
  
  # Medical adaptations
  medical_adaptations: true
  quality_dim: 4
  
# Pretrained weights configuration
# pretrained: true # Inherited from base
pretrained_cfg:
  url: "microsoft/swin_small_patch4_window7_224"
  num_classes: 1000
  input_size: [3, 224, 224]
  # Automatic adaptation for medical images

# Model-specific training adjustments
training_adjustments:
  base_lr_scale: 0.8  # Slightly lower LR for stability
  warmup_epochs: 20
  min_lr_ratio: 0.01
  layer_decay: 0.85  # Stronger layer-wise decay
