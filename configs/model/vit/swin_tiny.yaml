# Swin-Tiny configuration
# ~28M parameters, designed for efficient training on small medical datasets

defaults:
  - transformer/base_transformer
  # - _self_

name: swin_tiny
type: swin
# architecture: vit # Inherited from base_transformer as 'transformer'
params:
  # Architecture parameters
  # img_size: 224 # Inherited from base_transformer
  patch_size: 4 # Overrides base_transformer's 16
  in_chans: 1  # Grayscale medical images
  # num_classes: 2 # Inherited from base
  embed_dim: 96
  depths: [2, 2, 6, 2]
  num_heads: [3, 6, 12, 24]
  window_size: 7
  mlp_ratio: 4.0
  
  # Regularization
  drop_rate: 0.0
  attn_drop_rate: 0.0
  drop_path_rate: 0.2  # Stochastic depth
  
  # Advanced features
  qkv_bias: true
  qk_scale: null  # Use default sqrt(head_dim)
  ape: false  # No absolute position embedding (relative is enough)
  patch_norm: true
  use_checkpoint: false  # Enable for memory savings
  
  # Medical adaptations
  medical_adaptations: true
  quality_dim: 4
  
# Pretrained weights configuration
# pretrained: true # Inherited from base
pretrained_cfg:
  url: "microsoft/swin_tiny_patch4_window7_224"
  num_classes: 1000
  input_size: [3, 224, 224]
  # Weights will be adapted for grayscale 256x256

# Model-specific training adjustments
training_adjustments:
  base_lr_scale: 1.0  # Standard learning rate
  warmup_epochs: 20
  min_lr_ratio: 0.01
  layer_decay: 0.9  # Layer-wise LR decay for Swin
